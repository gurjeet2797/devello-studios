# Assisted Edit Tool - Workflow Flow Chart

## ğŸ¯ **Assisted Edit Tool Workflow**

### **Phase 1: Image Upload & Processing**
```
User Uploads Image
    â†“
ğŸ“ File Selection & Validation
    â†“
ğŸ” Upload Limit Check
    â†“
âœ… Image Standardization (HEIC â†’ JPEG)
    â†“
ğŸ“¤ Upload to Supabase Storage
    â†“
ğŸ“ Preview Generation & Container Setup
    â†“
ğŸ–¼ï¸ Parallel Caption Generation (Florence-2)
```

### **Phase 2: AI Assistant Initialization**
```
Caption Generated
    â†“
ğŸ¤– Assistant Receives Image Context
    â†“
ğŸ’¬ Personalized Greeting Based on Image
    â†“
ğŸ¯ Ready for User Interaction
```

### **Phase 3: Interactive Editing Workflow**
```
User Types Message
    â†“
ğŸ’¬ Message Sent to Gemini API
    â†“
ğŸ” Web Search for Reference Images
    â†“
ğŸ“¸ 4 Reference Images Returned
    â†“
ğŸ‘† User Clicks on Reference Image
    â†“
ğŸ¯ Hotspot Selection Modal
    â†“
ğŸ“ Hotspot Created on Image
    â†“
ğŸ”„ Reference Image Attached to Hotspot
```

### **Phase 4: Processing & Output**
```
User Clicks "Process"
    â†“
ğŸ¨ Combined Prompt Generation
    â†“
ğŸ¤– Gemini AI Processing
    â†“
âœ¨ Edited Image Generated
    â†“
ğŸ“Š Results Displayed
```

## ğŸ”„ **Key Interaction Points**

### **1. Image â†” Assistant Communication**
- **Caption**: Florence-2 generates detailed image description
- **Context**: Assistant uses caption for personalized responses
- **References**: Assistant suggests relevant images based on image content

### **2. User â†” Assistant Communication**
- **Messages**: Natural language requests for editing
- **Images**: 4 reference images per request
- **Hotspots**: Click-to-place editing points

### **3. Assistant â†” Processing Communication**
- **Prompts**: Combined editing instructions
- **References**: Attached reference images with coordinates
- **Output**: AI-processed final image

## ğŸ›ï¸ **State Management Flow**

```
Tool State Manager
    â”œâ”€â”€ Image States (originalSrc, processedSrc)
    â”œâ”€â”€ Processing States (isProcessing, isUploading)
    â”œâ”€â”€ Caption States (imageCaption, isCaptionPending)
    â”œâ”€â”€ Hotspot States (editHotspots, hotspotCounter)
    â”œâ”€â”€ History States (history, historyIndex)
    â””â”€â”€ UI States (showEnhanced, imageReady)
```

## ğŸ”§ **Technical Components**

### **Frontend Components**
- `AssistedEditStudio.js` - Main container
- `AssistedImageContainer.js` - Image display & hotspots
- `AssistedEditAssistantChat.js` - AI chat interface
- `AssistedEditHotspot.js` - Individual hotspot management

### **Hooks & Services**
- `useAssistedImageProcessing.js` - Image upload & caption generation
- `useAssistedProcessing.js` - AI processing logic
- `useToolState.js` - State management

### **API Endpoints**
- `/api/image-caption` - Florence-2 caption generation
- `/api/assistant/chat` - Gemini chat with web search
- `/api/predictions/general-edit` - AI image processing

## ğŸ¯ **User Experience Flow**

1. **Upload** â†’ User drags/drops or selects image
2. **Analyze** â†’ AI generates caption and shows "I'm viewing the image..."
3. **Greet** â†’ Assistant provides contextual greeting
4. **Request** â†’ User asks for specific changes or references
5. **Suggest** â†’ Assistant provides 4 reference images
6. **Place** â†’ User clicks reference and selects hotspot
7. **Process** â†’ AI applies changes and generates result
8. **Review** â†’ User can undo/redo or make additional changes

## ğŸ” **Debug Logging Focus**

### **Key Log Categories**
- `[ASSISTED_EDIT]` - Main tool operations
- `[ASSISTED_ASSISTANT]` - Chat interactions
- `[ASSISTANT_API]` - Gemini API responses
- `[IMAGE_CAPTION]` - Florence-2 processing

### **Critical Debug Points**
1. Image upload success/failure
2. Caption generation progress
3. Assistant message sending/receiving
4. Reference image selection
5. Hotspot creation and management
6. Final processing results
